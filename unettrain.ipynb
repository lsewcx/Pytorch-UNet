{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-09-30T01:15:19.496389Z","iopub.status.busy":"2024-09-30T01:15:19.495517Z","iopub.status.idle":"2024-09-30T01:15:34.418079Z","shell.execute_reply":"2024-09-30T01:15:34.417049Z","shell.execute_reply.started":"2024-09-30T01:15:19.496347Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'Pytorch-UNet'...\n","remote: Enumerating objects: 18387, done.\u001b[K\n","remote: Counting objects: 100% (8534/8534), done.\u001b[K\n","remote: Compressing objects: 100% (378/378), done.\u001b[K\n","remote: Total 18387 (delta 8198), reused 8490 (delta 8156), pack-reused 9853 (from 1)\u001b[K\n","Receiving objects: 100% (18387/18387), 190.27 MiB | 40.38 MiB/s, done.\n","Resolving deltas: 100% (13201/13201), done.\n","Updating files: 100% (2558/2558), done.\n"]}],"source":["!git clone https://github.com/lsewcx/Pytorch-UNet.git"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-09-30T03:41:20.256580Z","iopub.status.busy":"2024-09-30T03:41:20.255620Z","iopub.status.idle":"2024-09-30T03:41:48.085022Z","shell.execute_reply":"2024-09-30T03:41:48.084023Z","shell.execute_reply.started":"2024-09-30T03:41:20.256515Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: segmentation_models_pytorch in /opt/conda/lib/python3.10/site-packages (0.3.4)\n","Requirement already satisfied: efficientnet-pytorch==0.7.1 in /opt/conda/lib/python3.10/site-packages (from segmentation_models_pytorch) (0.7.1)\n","Requirement already satisfied: huggingface-hub>=0.24.6 in /opt/conda/lib/python3.10/site-packages (from segmentation_models_pytorch) (0.24.6)\n","Requirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (from segmentation_models_pytorch) (9.5.0)\n","Requirement already satisfied: pretrainedmodels==0.7.4 in /opt/conda/lib/python3.10/site-packages (from segmentation_models_pytorch) (0.7.4)\n","Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from segmentation_models_pytorch) (1.16.0)\n","Requirement already satisfied: timm==0.9.7 in /opt/conda/lib/python3.10/site-packages (from segmentation_models_pytorch) (0.9.7)\n","Requirement already satisfied: torchvision>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from segmentation_models_pytorch) (0.19.0)\n","Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from segmentation_models_pytorch) (4.66.4)\n","Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (2.4.0)\n","Requirement already satisfied: munch in /opt/conda/lib/python3.10/site-packages (from pretrainedmodels==0.7.4->segmentation_models_pytorch) (4.0.0)\n","Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from timm==0.9.7->segmentation_models_pytorch) (6.0.2)\n","Requirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from timm==0.9.7->segmentation_models_pytorch) (0.4.4)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.24.6->segmentation_models_pytorch) (3.15.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.24.6->segmentation_models_pytorch) (2024.6.1)\n","Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.24.6->segmentation_models_pytorch) (21.3)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.24.6->segmentation_models_pytorch) (2.32.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.24.6->segmentation_models_pytorch) (4.12.2)\n","Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision>=0.5.0->segmentation_models_pytorch) (1.26.4)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.24.6->segmentation_models_pytorch) (3.1.2)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (1.13.2)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (3.3)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (3.1.4)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.24.6->segmentation_models_pytorch) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.24.6->segmentation_models_pytorch) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.24.6->segmentation_models_pytorch) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.24.6->segmentation_models_pytorch) (2024.7.4)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (2.1.5)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (1.3.0)\n","Requirement already satisfied: albumentations in /opt/conda/lib/python3.10/site-packages (1.4.16)\n","Requirement already satisfied: numpy>=1.24.4 in /opt/conda/lib/python3.10/site-packages (from albumentations) (1.26.4)\n","Requirement already satisfied: scipy>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from albumentations) (1.14.0)\n","Requirement already satisfied: scikit-image>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from albumentations) (0.23.2)\n","Requirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from albumentations) (6.0.2)\n","Requirement already satisfied: pydantic>=2.7.0 in /opt/conda/lib/python3.10/site-packages (from albumentations) (2.8.2)\n","Requirement already satisfied: albucore==0.0.17 in /opt/conda/lib/python3.10/site-packages (from albumentations) (0.0.17)\n","Requirement already satisfied: eval-type-backport in /opt/conda/lib/python3.10/site-packages (from albumentations) (0.2.0)\n","Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /opt/conda/lib/python3.10/site-packages (from albumentations) (4.10.0.84)\n","Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.7.0->albumentations) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.20.1 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.7.0->albumentations) (2.20.1)\n","Requirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.7.0->albumentations) (4.12.2)\n","Requirement already satisfied: networkx>=2.8 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.21.0->albumentations) (3.3)\n","Requirement already satisfied: pillow>=9.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.21.0->albumentations) (9.5.0)\n","Requirement already satisfied: imageio>=2.33 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.21.0->albumentations) (2.34.1)\n","Requirement already satisfied: tifffile>=2022.8.12 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.21.0->albumentations) (2024.5.22)\n","Requirement already satisfied: packaging>=21 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.21.0->albumentations) (21.3)\n","Requirement already satisfied: lazy-loader>=0.4 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.21.0->albumentations) (0.4)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=21->scikit-image>=0.21.0->albumentations) (3.1.2)\n"]}],"source":["!pip install segmentation_models_pytorch\n","!pip install -U albumentations"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-09-30T03:48:21.716623Z","iopub.status.busy":"2024-09-30T03:48:21.716173Z","iopub.status.idle":"2024-09-30T03:48:50.421343Z","shell.execute_reply":"2024-09-30T03:48:50.420259Z","shell.execute_reply.started":"2024-09-30T03:48:21.716576Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 4170/4170 [00:28<00:00, 146.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["增强后的图像数量: 8340\n","增强后的掩码数量: 12510\n"]}],"source":["import os\n","import numpy as np\n","from PIL import Image\n","import albumentations as A\n","from tqdm import tqdm\n","\n","# 定义数据增强操作\n","augmentation = A.Compose([\n","    A.VerticalFlip(p=0.5),\n","    A.RandomRotate90(p=0.5),\n","    A.OneOf([\n","        A.ElasticTransform(alpha=120, sigma=120 * 0.05, alpha_affine=None, p=0.5),\n","        A.GridDistortion(p=0.5),\n","        A.OpticalDistortion(distort_limit=2, shift_limit=0.5, p=1)\n","    ], p=0.8),\n","    A.Resize(224, 224),\n","    A.RandomBrightnessContrast(p=0.8),\n","    A.RandomGamma(p=0.8)\n","], is_check_shapes=False)\n","\n","# 定义文件夹路径\n","images_dir = '/kaggle/working/Pytorch-UNet/NEU_Seg-main/images/training'\n","masks_dir = '/kaggle/working/Pytorch-UNet/NEU_Seg-main/annotations/training'\n","augmented_images_dir = '/kaggle/working/Pytorch-UNet/NEU_Seg-main/images/training'\n","augmented_masks_dir = '/kaggle/working/Pytorch-UNet/NEU_Seg-main/annotations/training'\n","\n","# 创建保存增强样本的文件夹\n","os.makedirs(augmented_images_dir, exist_ok=True)\n","os.makedirs(augmented_masks_dir, exist_ok=True)\n","\n","# 获取所有图像文件名\n","image_files = [f for f in os.listdir(images_dir) if os.path.isfile(os.path.join(images_dir, f))]\n","\n","# 对每个图像应用数据增强并保存\n","for image_file in tqdm(image_files):\n","    # 加载图像和掩码\n","    img = np.array(Image.open(os.path.join(images_dir, image_file)))\n","    mask = np.array(Image.open(os.path.join(masks_dir, image_file.replace('.jpg', '.png'))))\n","\n","    # 应用数据增强\n","    augmented = augmentation(image=img, mask=mask)\n","    augmented_img = augmented['image']\n","    augmented_mask = augmented['mask']\n","\n","    # 生成新的文件名\n","    base_name, ext = os.path.splitext(image_file)\n","    augmented_image_file = f\"{base_name}_aug{ext}\"\n","    augmented_mask_file = f\"{base_name}_aug_mask.png\"\n","\n","    # 保存增强后的图像和掩码\n","    Image.fromarray(augmented_img).save(os.path.join(augmented_images_dir, augmented_image_file))\n","    Image.fromarray(augmented_mask).save(os.path.join(augmented_masks_dir, augmented_mask_file))\n","\n","# 输出文件夹中的样本数量\n","augmented_image_files = [f for f in os.listdir(augmented_images_dir) if os.path.isfile(os.path.join(augmented_images_dir, f))]\n","augmented_mask_files = [f for f in os.listdir(augmented_masks_dir) if os.path.isfile(os.path.join(augmented_masks_dir, f))]\n","\n","print(f'增强后的图像数量: {len(augmented_image_files)}')\n","print(f'增强后的掩码数量: {len(augmented_mask_files)}')"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-09-30T01:16:10.868105Z","iopub.status.busy":"2024-09-30T01:16:10.867711Z","iopub.status.idle":"2024-09-30T01:16:13.798690Z","shell.execute_reply":"2024-09-30T01:16:13.797360Z","shell.execute_reply.started":"2024-09-30T01:16:10.868069Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/working/Pytorch-UNet\n"]}],"source":["%cd Pytorch-UNet\n","!rm -rf NEU_Seg-main\n","!unzip -q ceping/NEU_Seg-main.zip"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-09-30T01:16:13.801244Z","iopub.status.busy":"2024-09-30T01:16:13.800878Z","iopub.status.idle":"2024-09-30T01:16:16.000818Z","shell.execute_reply":"2024-09-30T01:16:15.999479Z","shell.execute_reply.started":"2024-09-30T01:16:13.801208Z"},"trusted":true},"outputs":[],"source":["!mv /kaggle/working/Pytorch-UNet/NEU_Seg-main/images/test/* /kaggle/working/Pytorch-UNet/NEU_Seg-main/images/training/\n","!mv /kaggle/working/Pytorch-UNet/NEU_Seg-main/annotations/test/* /kaggle/working/Pytorch-UNet/NEU_Seg-main/annotations/training/"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-30T03:48:56.169681Z","iopub.status.busy":"2024-09-30T03:48:56.168892Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/working/Pytorch-UNet\n","Already up to date.\n","INFO: Using device cuda\n","INFO: 模型的参数量: 67.16M\n","INFO: Network: Unet\n","INFO: Creating dataset with 8340 examples\n","INFO: Scanning mask files to determine unique values\n","  6%|██▍                                    | 509/8340 [00:04<00:54, 144.70it/s]"]}],"source":["%cd /kaggle/working/Pytorch-UNet\n","!git pull\n","!rm -rf /kaggle/working/Pytorch-UNet/model\n","!rm -rf best_model.pth best_model.pt\n","!python unet_train.py --classes 4 --batch-size 32 --epochs 100 --scale 1 --model UNet --v 10"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["%cd /kaggle/working/Pytorch-UNet\n","!git pull\n","!python unet_predict.py --model best_model.pth --scale 1 --model-name UNet -i NEU_Seg-main/images/test --batch-size 32"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!pip install segmentation-models-pytorch"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["%cd Pytorch-UNet\n","!git pull"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["%cd Pytorch-UNet\n","!rm -rf best_model.pth best_model.pt\n","!python train.py --classes 4 --batch-size 16 --epochs 100 --scale 1 --model selfnet --v 20"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import torch\n","import segmentation_models_pytorch as smp\n","\n","model = torch.load('/kaggle/working/Pytorch-UNet/ceping/best_model.pth')\n","\n","print(model)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# !rm -rf archive_name.zip /kaggle/working/Pytorch-UNet/test_predictions \n","# %cd /kaggle/working/Pytorch-UNet\n","# !mv best_model.pth ceping/best_model.pth\n","# !python predict.py --model  /kaggle/working/Pytorch-UNet/ceping/best_model.pth --scale 1 --model-name selfnet -i NEU_Seg-main/images/test\n","!rm -rf ceping/test_predictions\n","!mv test_predictions ceping/test_predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!rm -rf ceping/baseline_predictions\n","!mv test_predictions ceping/baseline_predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["%cd ceping\n","!python main.py\n","%cd .."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["%cd /kaggle/working/Pytorch-UNet\n","!rm -rf submsion.zip\n","!zip submsion.zip ceping/best_model.pth ceping/results.json  ceping/results.txt ceping/test_predictions/*"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["%cd /kaggle/working\n","!rm -rf predictions.zip\n","!zip predictions.zip /kaggle/working/Pytorch-UNet/test_predictions/*"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import os\n","os.chdir('/kaggle/working')\n","print(os.getcwd())\n","print(os.listdir(\"/kaggle/working\"))\n","from IPython.display import FileLink\n","FileLink(\"predictions.zip\")\n","# FileLink('Pytorch-UNet/submsion.zip')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!pip install segmentation-models-pytorch"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":5666109,"sourceId":9348126,"sourceType":"datasetVersion"},{"datasetId":5666216,"sourceId":9348273,"sourceType":"datasetVersion"}],"dockerImageVersionId":30762,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
